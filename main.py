from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Optional
import os
from dotenv import load_dotenv
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_core.documents import Document

# Load environment variables
load_dotenv()

app = FastAPI()

# Configuration
PERSIST_DIRECTORY = "./chroma_db"
DATA_DIR = "./data"

# Initialize Embeddings
embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")

# Load Vector Store
vectorstore = Chroma(
    persist_directory=PERSIST_DIRECTORY,
    embedding_function=embeddings,
    collection_name="travel_knowledge_base"
)

retriever = vectorstore.as_retriever(search_kwargs={"k": 10})

# Initialize LLM
llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash",
    temperature=0.7,
    max_tokens=2048,
    max_retries=2,
)

# Load all documents for Keyword Search
print("ğŸ“š Loading documents for Keyword Search...")
all_docs_data = vectorstore.get()
all_contents = all_docs_data['documents']
all_metadatas = all_docs_data['metadatas']

cached_docs = []
for i, content in enumerate(all_contents):
    metadata = all_metadatas[i] if all_metadatas else {}
    cached_docs.append(Document(page_content=content, metadata=metadata))

print(f"âœ… Loaded {len(cached_docs)} documents for Keyword Search.")


# ==================== ì¶œì²˜ ë§í¬ í¬ë§·íŒ… ====================

def format_source_citation(metadata):
    """ì‚¬ìš©ì ì¹œí™”ì ì¸ ì¶œì²˜ ë§í¬ ìƒì„±"""
    
    source_type = metadata.get('source_type', 'unknown')
    title = metadata.get('title', 'ì œëª© ì—†ìŒ')
    
    if source_type == 'youtube':
        url = metadata.get('url_full', '')
        timestamp = metadata.get('timestamp_str', '')
        
        if timestamp and url:
            return f"ğŸ“º [(ì˜ìƒ ë³´ê¸° - {timestamp})]({url})"
        elif url:
            return f"ğŸ“º [(ì˜ìƒ ë³´ê¸°)]({url})"
        else:
            return f"ğŸ“º {title}"
    
    elif source_type in ['blog', 'naver_blog']:
        url = metadata.get('url', metadata.get('original_url', ''))
        if url:
            return f"ğŸ“ [(ë¸”ë¡œê·¸ ê¸€ ë³´ê¸°)]({url})"
        else:
            return f"ğŸ“ {title}"
    
    else:
        url = metadata.get('url', metadata.get('original_url', ''))
        if url:
            return f"ğŸ”— [(ìì„¸íˆ ë³´ê¸°)]({url})"
        else:
            return f"ğŸ“„ {title}"


def format_docs_with_sources(docs):
    """ë¬¸ì„œ ë‚´ìš© + ì¶œì²˜ ë§í¬ í¬ë§·íŒ…"""
    
    if not docs:
        return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    formatted_parts = []
    
    for i, doc in enumerate(docs[:5], 1):  # ìµœëŒ€ 5ê°œë§Œ
        content = doc.page_content
        metadata = doc.metadata
        
        # ì¶œì²˜ ë§í¬ ìƒì„±
        source_citation = format_source_citation(metadata)
        
        # í¬ë§·íŒ…
        formatted = f"""[ì°¸ê³ ìë£Œ {i}]
{content}

ì¶œì²˜: {source_citation}
"""
        formatted_parts.append(formatted)
    
    return "\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n".join(formatted_parts)


# ==================== Hybrid Retrieval ====================

def retrieve_combined(query):
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: í‚¤ì›Œë“œ + ë²¡í„°"""
    
    print(f"ğŸ” Searching for: '{query}'")
    
    # 1. Keyword Search (ì •í™•í•œ ë§¤ì¹­)
    keyword_docs = []
    for doc in cached_docs:
        if query in doc.page_content:
            keyword_docs.append(doc)
    
    print(f"âœ… Keyword Search found: {len(keyword_docs)} documents")
    
    # 2. Vector Search (ì˜ë¯¸ ê¸°ë°˜)
    vector_docs = retriever.invoke(query)
    print(f"âœ… Vector Search found: {len(vector_docs)} documents")
    
    # 3. Combine & Deduplicate
    seen_content = set()
    final_docs = []
    
    # í‚¤ì›Œë“œ ë§¤ì¹­ ìš°ì„ 
    for doc in keyword_docs:
        if doc.page_content not in seen_content:
            final_docs.append(doc)
            seen_content.add(doc.page_content)
    
    # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€
    for doc in vector_docs:
        if doc.page_content not in seen_content:
            final_docs.append(doc)
            seen_content.add(doc.page_content)
    
    print(f"âœ… Final combined results: {len(final_docs[:10])} documents")
    
    return final_docs[:10]


# ==================== Prompt Template ====================

template = """ë‹¹ì‹ ì€ 'ì² ì‚°ëœë“œ(Iron Land)'ì˜ ì¹œê·¼í•œ ì—¬í–‰ ê°€ì´ë“œ AIì…ë‹ˆë‹¤.

ì œê³µëœ ì •ë³´:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{context}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ì‚¬ìš©ì ì§ˆë¬¸: {question}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ë‹µë³€ ì‘ì„± ê°€ì´ë“œ:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ ì•„ë˜ êµ¬ì¡°ë¡œ ë‹µë³€í•˜ì„¸ìš”:

**[ì¸ì‚¬ë§]**
"ì•ˆë…•í•˜ì„¸ìš”! [ì§ˆë¬¸ ë‚´ìš©]ì— ëŒ€í•´ ì•Œë ¤ë“œë¦´ê²Œìš” ğŸ˜Š"

**[ğŸ° ì œ ì—¬í–‰ ê²½í—˜ì—ì„œ]**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ìœ„ Contextì—ì„œ ì°¾ì€ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
- **ì¤‘ìš”**: ê° ì •ë³´ ë’¤ì— ì¶œì²˜ ë§í¬ë¥¼ ë°˜ë“œì‹œ í¬í•¨
  ì˜ˆì‹œ: "ì¬ë§ˆí˜¸í•‘ì€ ê°€ì¡± ì—¬í–‰ì— ì¢‹ìŠµë‹ˆë‹¤. [(ì˜ìƒ ë³´ê¸° - 51:23)](ë§í¬)"
- Contextì— ê´€ë ¨ ì •ë³´ê°€ ì—†ìœ¼ë©´:
  "ì œ ì—¬í–‰ ê¸°ë¡ì—ëŠ” ì´ ë¶€ë¶„ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì •ë³´ê°€ ì—†ë„¤ìš”."

**[ğŸ’¡ ì¶”ê°€ë¡œ ì•Œë©´ ì¢‹ì€ ì •ë³´]**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ì¼ë°˜ì ì¸ ë°°ê²½ ì§€ì‹ì´ë‚˜ ì—¬í–‰ íŒì„ ì œê³µí•˜ì„¸ìš”.
(Contextì— ì—†ì–´ë„ ì—¬í–‰ ìƒì‹ìœ¼ë¡œ ì•Œë ¤ì¤„ ìˆ˜ ìˆëŠ” ë‚´ìš©)

**[âš ï¸ ì°¸ê³ í•˜ì„¸ìš”]**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â€¢ ê°€ê²©, ì˜ì—…ì‹œê°„ ë“±ì€ ì‹œì¦Œ/í™˜ìœ¨ì— ë”°ë¼ ë³€ë™ë  ìˆ˜ ìˆì–´ìš”
â€¢ ì˜ˆì•½í•˜ì‹œê¸° ì „ì— ìµœì‹  ì •ë³´ë¥¼ í™•ì¸í•˜ì‹œëŠ” ê²ƒì„ ì¶”ì²œë“œë ¤ìš”
â€¢ ê¶ê¸ˆí•œ ì ì´ ë” ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”! ğŸ™‹â€â™‚ï¸

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì¶œì²˜ í‘œì‹œ ê·œì¹™ (ë§¤ìš° ì¤‘ìš”):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… ì¢‹ì€ ì˜ˆ:
"ì¬ë§ˆí˜¸í•‘ì€ ê°€ì¡± ë‹¨ìœ„ ì—¬í–‰ê°ì—ê²Œ ì¶”ì²œë“œë ¤ìš”. [(ì˜ìƒ ë³´ê¸° - 51:23)](https://youtube.com/...)"

âŒ ë‚˜ìœ ì˜ˆ:
"ì¬ë§ˆí˜¸í•‘ì€ ê°€ì¡± ë‹¨ìœ„ì— ì¢‹ìŠµë‹ˆë‹¤. (ì¶œì²˜: 202507_youtube_cebu_hopping_002.json)"

ì¶œì²˜ëŠ” ë°˜ë“œì‹œ:
1. ìœ íŠœë¸Œ ë§í¬ + íƒ€ì„ìŠ¤íƒ¬í”„ ë˜ëŠ”
2. ë¸”ë¡œê·¸ ì›ë¬¸ ë§í¬ë¡œ í‘œì‹œ

íŒŒì¼ëª…(.json)ì€ ì ˆëŒ€ í‘œì‹œí•˜ì§€ ë§ˆì„¸ìš”!

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ì¹œì ˆí•˜ê³  ë”°ëœ»í•œ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ëª¨ë¥´ëŠ” ê±´ ì†”ì§í•˜ê²Œ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ì„¸ìš”!
"""

prompt = ChatPromptTemplate.from_template(template)


# ==================== RAG Chain ====================

rag_chain = (
    {
        "context": RunnableLambda(retrieve_combined) | RunnableLambda(format_docs_with_sources),
        "question": RunnablePassthrough()
    }
    | prompt
    | llm
    | StrOutputParser()
)


# ==================== API Endpoints ====================

@app.get("/")
def read_root():
    return {
        "status": "ok", 
        "message": "Iron Land Travel AI (Enhanced with Source Links)",
        "version": "2.0"
    }


class ChatRequest(BaseModel):
    query: str
    history: Optional[List[dict]] = None


class ChatResponse(BaseModel):
    answer: str
    sources: List[dict]


@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    try:
        print(f"\n{'='*60}")
        print(f"ğŸ“¨ New query: {request.query}")
        print(f"{'='*60}")
        
        # Retrieve documents
        docs = retrieve_combined(request.query)
        
        # Generate answer
        answer = rag_chain.invoke(request.query)
        
        # Extract sources with full metadata
        sources = []
        for doc in docs[:5]:  # ìµœëŒ€ 5ê°œ
            source_info = {
                "source_type": doc.metadata.get("source_type", "unknown"),
                "title": doc.metadata.get("title", ""),
                "url": doc.metadata.get("url_full", doc.metadata.get("url", "")),
                "url_full": doc.metadata.get("url_full", ""),
                "original_url": doc.metadata.get("original_url", ""),
                "timestamp_str": doc.metadata.get("timestamp_str", ""),
            }
            sources.append(source_info)
        
        print(f"âœ… Answer generated with {len(sources)} sources")
        
        return ChatResponse(answer=answer, sources=sources)
    
    except Exception as e:
        print(f"âŒ Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    print("\n" + "="*60)
    print("ğŸ° Iron Land Travel AI Server Starting...")
    print("="*60 + "\n")
    uvicorn.run(app, host="0.0.0.0", port=8000)
